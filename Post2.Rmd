---
title: "Post2"
author: "Grace Puryear"
date: "December 9, 2018"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Read in data


```{r cars}
#install.packages("readxl")
library(readxl)
library(caret)
library(e1071)
user_knowledge <- as.data.frame(read_excel("User_Knowledge_test.xls",sheet="Training_Data",range="A1:F259"))
head(user_knowledge)
# STG (The degree of study time for goal object materials), (input value)
# SCG (The degree of repetition number of user for goal object materials) (input value)
# STR (The degree of study time of user for related objects with goal object) (input value)
# LPR (The exam performance of user for related objects with goal object) (input value)
# PEG (The exam performance of user for goal objects) (input value)
# UNS (The knowledge level of user) (target value)
# Very Low: 24
# Low: 83
# Middle: 88
# High 63

```



***Clustering Method***
```{r}
user_knowledge[,6] <- as.factor(user_knowledge[,6])
plot(user_knowledge[,1:5],
     pch=c("o","+","*","^")[user_knowledge$UNS],
     col=c("red","green3","blue","orange")[user_knowledge$UNS])


#There appears to be a clear distinction between the 4 groups.

```


```{r}
High <- user_knowledge[which(user_knowledge$UNS=="High"),]
Low <- user_knowledge[which(user_knowledge$UNS=="Low"),]
Middle <- user_knowledge[which(user_knowledge$UNS=="Middle"),]
vlow <- user_knowledge[which(user_knowledge$UNS=="very_low"),]


col_means <- as.data.frame(rbind(colMeans(High[,1:5]),colMeans(Middle[,1:5]),colMeans(Low[,1:5]),colMeans(vlow[,1:5])))
row.names(col_means)[1] <- "High"
row.names(col_means)[2] <- "Middle"
row.names(col_means)[3] <- "Low"
row.names(col_means)[4] <- "Very Low"
col_means

#It appears that the high knowledge users have (almost) the highest averages of each variable across the board.The only one that the high knowledge users slightly trail in is 'STR', or the degree of study time of user for related objects with goal object.The middle knowledge users contain the second highest value in each column, except fot the 'LPR' variable, or the exam performance of user for related objects with goal object. 
```

##K-Medoids
```{r}

library(cluster)

# group into 3 clusters
pam.result <- pam(user_knowledge[,1:5], 4)

table(pam.result$clustering, user_knowledge$UNS)

par(mar=c(4,4,1,1))
plot(pam.result)

#It appears there is a lot of overlap in the 4 target values. 
```


##determining number of clusters
```{r}
library(fpc)
set.seed(1);pamk.result <- pamk(user_knowledge[,1:5])

# check clustering against actual user knowledge
table(pamk.result$pamobject$clustering, user_knowledge$UNS)

par(mar=c(4,4,1,1))
plot(pamk.result$pamobject)
pamk.result$pamobject$medoids
#pamk tells us that 2 clusters is best here. However, there is still no clear distinction. It appears that cluster 1 is the low and very low knowledge users. Cluster 2 is the middle/high knowledge users.
#Cluster 1 has a higher average degree of study time, higer average degree of repetition for goal object materials, and higher average exam performance for related objects with goal object. Cluster 2 has higher average degree of study time for related objects with goal object and a higher exam performance for goal objects.
```



***Doing a classification based approach***
```{r}
user_test <- as.data.frame(read_excel("User_Knowledge_test.xls",sheet="Test_Data",range="A1:F146"))
user_test$UNS <- as.factor(user_test$UNS)


# Train a naive Bayes model (based on the training set)
fit_nb <- naiveBayes(UNS ~ ., user_knowledge)

# Check performance (based on the test set)
table(predict(fit_nb, user_test), user_test$UNS) # 122 out of 145 (84%) correct

```




